# ğŸ—ºï¸â€¯ProjetÂ : ModÃ¨le invariant pour lâ€™estimation de la longueur optimale dâ€™un TSP

> **TL;DR**â€¯: Ce dÃ©pÃ´t contient tout le nÃ©cessaire pour entraÃ®ner, tester et analyser un modÃ¨le apprenant Ã  prÃ©dire la distance optimale (ou son score) dâ€™instances TSP de 30â€¯Ã â€¯50Â nÅ“uds, tout en restant invariant aux transformations euclidiennes (rotation, translation, permutation de sommetsâ€¦).

---

## 1. ContexteÂ & objectifs

Les algorithmes exacts pour le *Travelingâ€¯Salesmanâ€¯Problem* (TSP) deviennent vite inabordables sur de grandes instances. Lâ€™objectif est donc de **regresser** la longueur optimale dâ€™un tour via un rÃ©seau de neurones, tout en apprenant des invariances qui garantissent quâ€™une instance tournÃ©e, translatÃ©e ou permutÃ©e produira laâ€¯mÃªme prÃ©diction.

- **Dataset dâ€™entraÃ®nement**Â : `tsp_30_50.json` (â‰ˆâ€¯80â€¯k instances).
- **Dataset de test**Â Â Â Â Â Â Â Â : `tsp_test_20k_30_50.json` (20â€¯k instances, jamais vues).

---

## 2. Structure attendue des datasets

Chaque fichier JSON est **une liste** dâ€™entrÃ©esÂ :

```json
{
  "id": 0,
  "n_points": 34,
  "points": [[x1, y1], [x2, y2], â€¦],
  "opt_tour": [0, 24, 11, â€¦, 0],
  "score": 5.1610150595416115   // parfois nommÃ© "opt_dist" ou "opt_dist_true"
}
```

> **âš ï¸Â Attentionâ€¯:** Si votre dump emploie `"opt_dist"` (ou `"opt_dist_true"`) Ã  la place de `"score"`, adaptez les scripts en consÃ©quenceâ€¯; les exemples ciâ€‘dessous le gÃ¨rent par dÃ©faut.

---

## 3. Workflow rapide (datasets dÃ©jÃ  gÃ©nÃ©rÃ©s)

> TrÃ¨s bonne questionâ€¯! Voici les grandes Ã©tapes **Ã  partir du moment oÃ¹ vous disposez dÃ©jÃ ** des fichiersÂ `/home/dcbrain/Bureau/ml_rd/data/tsp_dataset/tsp_30_50.json` et `â€¦/tsp_test_20k_30_50.json`.

### 3.1Â PrÃ©paration des donnÃ©es dâ€™entraÃ®nement
- VÃ©rifiez la prÃ©sence desâ€¯clÃ©sÂ `points`, `opt_tour`, `score`/`opt_dist`.
- Mettez Ã  jour `load_dataset()` si besoin pour mapper `opt_dist`Â â†’Â `score`.

### 3.2Â EntraÃ®nement du modÃ¨le
```bash
python src/train_invariance.py     --dataset /home/dcbrain/Bureau/ml_rd/data/tsp_dataset/tsp_30_50.json     --batch_size 256     --epochs 50     --learning_rate 1e-3     --output_dir outputs/train
```
Le scriptÂ :
- normalise les longueurs via **StandardScaler**â€¯;
- applique des transformations (rotations, translations, permutations) *onâ€‘theâ€‘fly*â€¯;
- sauvegardeâ€¯:
  - `tsp_invariant_model.pt`â€¯;
  - `scaler.pkl`â€¯;
  - `metrics.json`, `training_history.png`.

### 3.3Â Ã‰valuation sur le dataset de test
```bash
python src/evaluate_model.py     --model outputs/train/tsp_invariant_model.pt     --scaler outputs/train/scaler.pkl     --dataset /home/dcbrain/Bureau/ml_rd/data/tsp_dataset/tsp_test_20k_30_50.json     --output_dir outputs/eval
```
Le script calcule la **MSE**, les diffÃ©rences absolues/relatives et gÃ©nÃ¨re des histogrammes (`invariance_metrics_eval.png`).

### 3.4Â Analyse & interprÃ©tation
- InspectezÂ `outputs/eval/metrics.json`â€¯: *mse*, *mean_abs_diff*, *mean_rel_diff*, etc. doivent Ãªtre faibles (â‰ˆâ€¯0).
- (Optionnel) comparez avec dâ€™autres architectures ou tailles de graphes.

### 3.5Â RÃ©sumÃ© visuel
```
[DATASETS PRÃŠTS]
      |
      v
[ENTRAÃNEMENT]
  - train_invariance.py
  - Sauvegarde modÃ¨le + scaler
      |
      v
[Ã‰VALUATION]
  - evaluate_model.py
  - Sur le dataset de test
      |
      v
[ANALYSE]
  - InterprÃ©tation des mÃ©triques
```

ğŸ‘‰ **Besoin dâ€™automatiser toute la chaÃ®neâ€¯?** Ditesâ€‘le et je vous fournis un `Makefile` ou un *workflow*Â CI/CD.

---

## 4. Installation rapide

```bash
# 1Â â€“ Environnement PythonÂ â‰¥â€¯3.10
python -m venv .venv && source .venv/bin/activate

# 2Â â€“ DÃ©pendances
pip install -r requirements.txt
```

### 4.1Â DÃ©pendances principales

| Paquet          | Version testÃ©e |
|-----------------|----------------|
| PyTorch         | 2.3.0          |
| scikitâ€‘learn    | 1.5.0          |
| numpy           | 1.28.0         |
| matplotlib      | 3.9.0          |
| tqdm            | 4.66           |
| pythonâ€‘dotenv   | 1.0            |

---

## 5. Arborescence recommandÃ©e

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ tsp_dataset/
â”‚       â”œâ”€â”€ tsp_30_50.json
â”‚       â””â”€â”€ tsp_test_20k_30_50.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_invariance.py
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â”œâ”€â”€ transformations.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ eval/
â””â”€â”€ README.md
```

---

## 6. ReproductibilitÃ©

- Tous les scripts acceptent `--seed` (dÃ©fautâ€¯:Â `42`).
- Les hachages Git et `torch.__config__.show()` sont loggÃ©s pour garantir lâ€™auditabilitÃ©.

---

## 7. Instructions Â«â€¯Codexâ€¯Â» (OpenAI) âœ¨

Pour gÃ©nÃ©rer ou complÃ©ter du code avec ChatGPT/CodexÂ :
1. **Contextualisez** votre prompt (signature de fonction, contraintes temporellesâ€¦).
2. **SpÃ©cifiez** les limitesâ€¯: complexitÃ©, device, style PEPâ€‘8.
3. **Validez** via `pytest` ou un petit notebook avant de pousser.

> ExempleÂ :
> Â«â€¯Ã‰cris une fonction PyTorch `compute_tour_length(points, tour)` qui calcule la distance totale. Utilise seulement `torch` et vectorise au maximum.â€¯Â»

---

## 8. Roadmap (suggestion)

- [ ] Curriculum dâ€™apprentissage pour des graphes >â€¯50Â nÅ“uds.
- [ ] Exploration dâ€™un *GNN* 
- [ ] Benchmark vs. heuristiquesÂ (LKH, Concorde).

---

## 9. Licence & citation

Sous licence **MIT**. Merci de citerÂ :

```text
@misc{tsp_invariant_2025,
  author       = {VotreÂ Nom},
  title        = {A learningâ€‘based invariant estimator for TSP tour length},
  year         = 2025,
  howpublished = {GitHub},
  url          = {https://github.com/username/tsp-invariant-model}
}
```

---

### Bonnes expÃ©rimentationsâ€¯! ğŸ§©
